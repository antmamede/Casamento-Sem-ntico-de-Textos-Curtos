{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b534922",
   "metadata": {},
   "source": [
    "# Importando Pacotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3891f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "import nltk\n",
    "import strsimpy\n",
    "import numpy as np\n",
    "from strsimpy.normalized_levenshtein import NormalizedLevenshtein\n",
    "from strsimpy.jaro_winkler import JaroWinkler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1096ba3",
   "metadata": {},
   "source": [
    "# Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "687c2822",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_bases = \"C:\\\\Users\\\\aamma\\\\OneDrive\\\\ENCE\\\\TCC\\\\REFAZENDO EXPERIMENTO\\\\Bases\"\n",
    "path_embeddings = \"C:\\\\Users\\\\aamma\\\\OneDrive\\\\ENCE\\\\TCC\\\\REFAZENDO EXPERIMENTO\\\\Embeddings\"\n",
    "path_resultados = \"C:\\\\Users\\\\aamma\\\\OneDrive\\\\ENCE\\\\TCC\\\\REFAZENDO EXPERIMENTO\\\\Resultados\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f286899",
   "metadata": {},
   "source": [
    "# Leitura de Bases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd8cee5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(path_bases)\n",
    "descricoes_pof = pd.read_excel(\"Descricoes_POF_g4.xlsx\")\n",
    "descricoes_snipc = pd.read_excel(\"Descricoes_SNIPC_g4.xlsx\")\n",
    "descricoes_pof = descricoes_pof.values.tolist() # Converte dataframe para lista de listas\n",
    "descricoes_snipc = descricoes_snipc.values.tolist() # Coverte dataframe para lista de listas\n",
    "descricoes_pof = [item for sublist in descricoes_pof for item in sublist] # Converte lista de listas para lista\n",
    "descricoes_snipc = [item for sublist in descricoes_snipc for item in sublist] # Converte lista de listas para lista"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d87e2d",
   "metadata": {},
   "source": [
    "# Criando Matrizes de Similaridade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c86b2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Levenshtein\n",
    "df_levenshtein = np.zeros((len(descricoes_pof), len(descricoes_snipc)))\n",
    "df_levenshtein = pd.DataFrame(df_levenshtein, columns = descricoes_snipc,\n",
    "index = descricoes_pof)\n",
    "\n",
    "## Jaro\n",
    "df_jaro = np.zeros((len(descricoes_pof), len(descricoes_snipc)))\n",
    "df_jaro = pd.DataFrame(df_jaro, columns = descricoes_snipc,\n",
    "index = descricoes_pof)\n",
    "\n",
    "## Jaccard\n",
    "df_jaccard = np.zeros((len(descricoes_pof), len(descricoes_snipc)))\n",
    "df_jaccard = pd.DataFrame(df_jaccard, columns = descricoes_snipc,\n",
    "index = descricoes_pof)\n",
    "\n",
    "## TF-IDF\n",
    "df_tfidf = np.zeros((len(descricoes_pof), len(descricoes_snipc)))\n",
    "df_tfidf = pd.DataFrame(df_tfidf, columns = descricoes_snipc,\n",
    "index = descricoes_pof)\n",
    "\n",
    "## Word2Vec\n",
    "df_word2vec_soma = np.zeros((len(descricoes_pof), len(descricoes_snipc)))\n",
    "df_word2vec_soma = pd.DataFrame(df_word2vec_soma, columns = descricoes_snipc,\n",
    "index = descricoes_pof)\n",
    "df_word2vec_media = np.zeros((len(descricoes_pof), len(descricoes_snipc)))\n",
    "df_word2vec_media = pd.DataFrame(df_word2vec_media, columns = descricoes_snipc,\n",
    "index = descricoes_pof)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da119136",
   "metadata": {},
   "source": [
    "# Calculando Similaridade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffb4f21",
   "metadata": {},
   "source": [
    "## Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cabc514d",
   "metadata": {},
   "outputs": [],
   "source": [
    "levenshtein = NormalizedLevenshtein()\n",
    "contador = 0\n",
    "for palavra_pof in df_levenshtein.index:\n",
    "    for palavra_snipc in df_levenshtein.columns:\n",
    "        df_levenshtein.at[palavra_pof, palavra_snipc] = levenshtein.similarity(palavra_pof, palavra_snipc)\n",
    "    contador = contador + 1\n",
    "    if contador % 700 == 0 or contador == 3305:\n",
    "        print(contador / df_levenshtein.shape[0] * 100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "065a85b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_resultados = \"C:\\\\Users\\\\aamma\\\\OneDrive\\\\ENCE\\\\TCC\\\\REFAZENDO EXPERIMENTO\\\\Resultados\"\n",
    "os.chdir(path_resultados)\n",
    "df_levenshtein.to_excel(\"Levenshtein_g4_MS.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1151d0e0",
   "metadata": {},
   "source": [
    "## Jaro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6872f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "jaro = JaroWinkler()\n",
    "contador = 0\n",
    "for palavra_pof in df_jaro.index:\n",
    "    for palavra_snipc in df_jaro.columns:\n",
    "        df_jaro.at[palavra_pof, palavra_snipc] = jaro.similarity(palavra_pof, palavra_snipc)\n",
    "    contador = contador + 1\n",
    "    if contador % 700 == 0 or contador == 3305:\n",
    "        print(contador / df_jaro.shape[0] * 100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1091c365",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(path_resultados)\n",
    "df_jaro.to_excel(\"Jaro_g4_MS.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663a17c6",
   "metadata": {},
   "source": [
    "## Jaccard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e901e379",
   "metadata": {},
   "outputs": [],
   "source": [
    "contador = 0\n",
    "for palavra_pof in df_jaccard.index:\n",
    "    for palavra_snipc in df_jaccard.columns:\n",
    "        tok_pof = set(palavra_pof.split())\n",
    "        tok_snipc = set(palavra_snipc.split())\n",
    "        numerador = tok_pof & tok_snipc\n",
    "        denominador = tok_pof | tok_snipc\n",
    "        df_jaccard.at[palavra_pof, palavra_snipc] = len(numerador) / len(denominador)\n",
    "    contador = contador + 1\n",
    "    if contador % 700 == 0 or contador == 3305:\n",
    "        print(contador / df_jaccard.shape[0] * 100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c62b68ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(path_resultados)\n",
    "df_jaccard.to_excel(\"Jaccard_g4_MS.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241ff78f",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1dde7212",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Juntando Todas as Descrições e Removendo duplicatas\n",
    "todas_descricoes = descricoes_pof + descricoes_snipc\n",
    "todas_descricoes = pd.Series(todas_descricoes).drop_duplicates().to_list()\n",
    "\n",
    "# Calculando valores TF-IDF\n",
    "tfidf_matrix = vectorizer.fit_transform(todas_descricoes)\n",
    "\n",
    "# Transformando Matriz TF-IDF em DF\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), index=todas_descricoes, columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# Filtrando por pesquisas\n",
    "tfidf_snipc = tfidf_df.filter(items = descricoes_snipc, axis = 0)\n",
    "tfidf_pof = tfidf_df.filter(items = descricoes_pof, axis = 0)\n",
    "\n",
    "## Calculando Cosseno e transformando em DF\n",
    "cosine_sim = cosine_similarity(tfidf_pof, tfidf_snipc)\n",
    "df_tfidf = pd.DataFrame(cosine_sim, index = descricoes_pof, columns = descricoes_snipc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a598184",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(path_resultados)\n",
    "df_tfidf.to_excel(\"TFIDF_g4_MS.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e705dc",
   "metadata": {},
   "source": [
    "# Word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d0df050",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(path_embeddings)\n",
    "os.getcwd()\n",
    "model = KeyedVectors.load_word2vec_format(\"skip_s300.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89d56093",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(path_bases)\n",
    "tokens_all = pd.read_excel(\"Tokens_All_g4.xlsx\")\n",
    "tokens_all = tokens_all.values.tolist()\n",
    "tokens_all = [item for sublist in tokens_all for item in sublist]\n",
    "vocab_set = set(model.index_to_key)\n",
    "keep_set = set(tokens_all)\n",
    "drop_set = vocab_set - keep_set\n",
    "for word in drop_set:\n",
    "    del model.key_to_index[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0927d7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_nc = pd.read_excel(\"Tokens_All_NC_g4.xlsx\")\n",
    "tokens_nc = tokens_nc.values.tolist()\n",
    "tokens_nc = [item for sublist in tokens_nc for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e262b74d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dominni', 'passadeiro', '15', 'tosadeira', 'totolec', 'trimania']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f79b57ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz_aux = np.zeros((300, ), dtype = \"float32\")\n",
    "for token in tokens_nc:\n",
    "    model[token] = matriz_aux"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6d25e9",
   "metadata": {},
   "source": [
    "## Soma de Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b7ba3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_soma(sentence, model, num_features, word_set):\n",
    "    words = sentence.split()\n",
    "    feature_vec = np.zeros((num_features, ), dtype = \"float32\")\n",
    "    for word in words:\n",
    "        if word in word_set:\n",
    "            feature_vec = np.add(feature_vec, model[word])\n",
    "    model[sentence] = feature_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5deb9314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 %\n",
      "2.525252525252525 %\n",
      "5.05050505050505 %\n",
      "7.575757575757576 %\n",
      "10.1010101010101 %\n",
      "12.626262626262626 %\n",
      "15.151515151515152 %\n",
      "17.67676767676768 %\n",
      "20.2020202020202 %\n",
      "22.727272727272727 %\n",
      "25.252525252525253 %\n",
      "27.77777777777778 %\n",
      "30.303030303030305 %\n",
      "32.82828282828283 %\n",
      "35.35353535353536 %\n",
      "37.878787878787875 %\n",
      "40.4040404040404 %\n",
      "42.92929292929293 %\n",
      "45.45454545454545 %\n",
      "47.97979797979798 %\n",
      "50.505050505050505 %\n",
      "53.03030303030303 %\n",
      "55.55555555555556 %\n",
      "58.080808080808076 %\n",
      "60.60606060606061 %\n",
      "63.13131313131313 %\n",
      "65.65656565656566 %\n",
      "68.18181818181817 %\n",
      "70.70707070707071 %\n",
      "73.23232323232324 %\n",
      "75.75757575757575 %\n",
      "78.28282828282829 %\n",
      "80.8080808080808 %\n",
      "83.33333333333334 %\n",
      "85.85858585858585 %\n",
      "88.38383838383838 %\n",
      "90.9090909090909 %\n",
      "93.43434343434343 %\n",
      "95.95959595959596 %\n",
      "98.48484848484848 %\n"
     ]
    }
   ],
   "source": [
    "word_set = set(model.index_to_key)\n",
    "todas_descricoes = descricoes_pof + descricoes_snipc\n",
    "contador = 0\n",
    "for descricao in todas_descricoes:\n",
    "    embedding_soma(descricao, model, 300, word_set)\n",
    "    if contador % 10 == 0 or contador == 4592:\n",
    "        print(contador / len(todas_descricoes) * 100, \"%\")\n",
    "    contador = contador + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d88cdf38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.571428571428571 %\n",
      "7.142857142857142 %\n",
      "10.714285714285714 %\n",
      "14.285714285714285 %\n",
      "17.857142857142858 %\n",
      "21.428571428571427 %\n",
      "25.0 %\n",
      "28.57142857142857 %\n",
      "32.142857142857146 %\n",
      "35.714285714285715 %\n",
      "39.285714285714285 %\n",
      "42.857142857142854 %\n",
      "46.42857142857143 %\n",
      "50.0 %\n",
      "53.57142857142857 %\n",
      "57.14285714285714 %\n",
      "60.71428571428571 %\n",
      "64.28571428571429 %\n",
      "67.85714285714286 %\n",
      "71.42857142857143 %\n",
      "75.0 %\n",
      "78.57142857142857 %\n",
      "82.14285714285714 %\n",
      "85.71428571428571 %\n",
      "89.28571428571429 %\n",
      "92.85714285714286 %\n",
      "96.42857142857143 %\n",
      "100.0 %\n"
     ]
    }
   ],
   "source": [
    "contador = 0\n",
    "for palavra_pof in df_word2vec_soma.index:\n",
    "    for palavra_snipc in df_word2vec_soma.columns:\n",
    "        df_word2vec_soma.at[palavra_pof, palavra_snipc] = model.similarity(palavra_pof, palavra_snipc)\n",
    "    contador = contador + 1\n",
    "    if contador % 10 == 0 or contador == 3376:\n",
    "        print(contador / df_word2vec_soma.shape[0] * 100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f67716f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(path_resultados)\n",
    "df_word2vec_soma.to_excel(\"Word2VecSoma_g4_MS.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8dbeb53",
   "metadata": {},
   "source": [
    "## Word2Vec Média"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3ded131a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_media(sentence, model, num_features, word_set):\n",
    "    words = sentence.split()\n",
    "    n_words = 0\n",
    "    feature_vec = np.zeros((num_features, ), dtype = \"float32\")\n",
    "    for word in words:\n",
    "        if word in word_set:\n",
    "            feature_vec = np.add(feature_vec, model[word])\n",
    "            n_words = n_words + 1\n",
    "    model[sentence] = feature_vec / n_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "406dc9f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 %\n",
      "2.525252525252525 %\n",
      "5.05050505050505 %\n",
      "7.575757575757576 %\n",
      "10.1010101010101 %\n",
      "12.626262626262626 %\n",
      "15.151515151515152 %\n",
      "17.67676767676768 %\n",
      "20.2020202020202 %\n",
      "22.727272727272727 %\n",
      "25.252525252525253 %\n",
      "27.77777777777778 %\n",
      "30.303030303030305 %\n",
      "32.82828282828283 %\n",
      "35.35353535353536 %\n",
      "37.878787878787875 %\n",
      "40.4040404040404 %\n",
      "42.92929292929293 %\n",
      "45.45454545454545 %\n",
      "47.97979797979798 %\n",
      "50.505050505050505 %\n",
      "53.03030303030303 %\n",
      "55.55555555555556 %\n",
      "58.080808080808076 %\n",
      "60.60606060606061 %\n",
      "63.13131313131313 %\n",
      "65.65656565656566 %\n",
      "68.18181818181817 %\n",
      "70.70707070707071 %\n",
      "73.23232323232324 %\n",
      "75.75757575757575 %\n",
      "78.28282828282829 %\n",
      "80.8080808080808 %\n",
      "83.33333333333334 %\n",
      "85.85858585858585 %\n",
      "88.38383838383838 %\n",
      "90.9090909090909 %\n",
      "93.43434343434343 %\n",
      "95.95959595959596 %\n",
      "98.48484848484848 %\n"
     ]
    }
   ],
   "source": [
    "word_set = set(model.index_to_key)\n",
    "todas_descricoes = descricoes_pof + descricoes_snipc\n",
    "contador = 0\n",
    "for descricao in todas_descricoes:\n",
    "    embedding_media(descricao, model, 300, word_set)\n",
    "    if contador % 10 == 0 or contador == 4592:\n",
    "        print(contador / len(todas_descricoes) * 100, \"%\")\n",
    "    contador = contador + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5ec38f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.571428571428571 %\n",
      "7.142857142857142 %\n",
      "10.714285714285714 %\n",
      "14.285714285714285 %\n",
      "17.857142857142858 %\n",
      "21.428571428571427 %\n",
      "25.0 %\n",
      "28.57142857142857 %\n",
      "32.142857142857146 %\n",
      "35.714285714285715 %\n",
      "39.285714285714285 %\n",
      "42.857142857142854 %\n",
      "46.42857142857143 %\n",
      "50.0 %\n",
      "53.57142857142857 %\n",
      "57.14285714285714 %\n",
      "60.71428571428571 %\n",
      "64.28571428571429 %\n",
      "67.85714285714286 %\n",
      "71.42857142857143 %\n",
      "75.0 %\n",
      "78.57142857142857 %\n",
      "82.14285714285714 %\n",
      "85.71428571428571 %\n",
      "89.28571428571429 %\n",
      "92.85714285714286 %\n",
      "96.42857142857143 %\n",
      "100.0 %\n"
     ]
    }
   ],
   "source": [
    "contador = 0\n",
    "for palavra_pof in df_word2vec_media.index:\n",
    "    for palavra_snipc in df_word2vec_media.columns:\n",
    "        df_word2vec_media.at[palavra_pof, palavra_snipc] = model.similarity(palavra_pof, palavra_snipc)\n",
    "    contador = contador + 1\n",
    "    if contador % 10 == 0 or contador == 3376:\n",
    "        print(contador / df_word2vec_media.shape[0] * 100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "877c7a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(path_resultados)\n",
    "df_word2vec_media.to_excel(\"Word2VecMedia_g4_MS.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339c9226",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b2bf110c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "280"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6387343a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8838ec3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
