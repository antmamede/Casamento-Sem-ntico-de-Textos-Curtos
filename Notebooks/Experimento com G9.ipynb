{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b534922",
   "metadata": {},
   "source": [
    "# Importando Pacotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3891f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "import nltk\n",
    "import strsimpy\n",
    "import numpy as np\n",
    "from strsimpy.normalized_levenshtein import NormalizedLevenshtein\n",
    "from strsimpy.jaro_winkler import JaroWinkler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1096ba3",
   "metadata": {},
   "source": [
    "# Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "687c2822",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_bases = \"C:\\\\Users\\\\aamma\\\\OneDrive\\\\ENCE\\\\TCC\\\\REFAZENDO EXPERIMENTO\\\\Bases\"\n",
    "path_embeddings = \"C:\\\\Users\\\\aamma\\\\OneDrive\\\\ENCE\\\\TCC\\\\REFAZENDO EXPERIMENTO\\\\Embeddings\"\n",
    "path_resultados = \"C:\\\\Users\\\\aamma\\\\OneDrive\\\\ENCE\\\\TCC\\\\REFAZENDO EXPERIMENTO\\\\Resultados\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f286899",
   "metadata": {},
   "source": [
    "# Leitura de Bases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd8cee5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(path_bases)\n",
    "descricoes_pof = pd.read_excel(\"Descricoes_POF_g9.xlsx\")\n",
    "descricoes_snipc = pd.read_excel(\"Descricoes_SNIPC_g9.xlsx\")\n",
    "descricoes_pof = descricoes_pof.values.tolist() # Converte dataframe para lista de listas\n",
    "descricoes_snipc = descricoes_snipc.values.tolist() # Coverte dataframe para lista de listas\n",
    "descricoes_pof = [item for sublist in descricoes_pof for item in sublist] # Converte lista de listas para lista\n",
    "descricoes_snipc = [item for sublist in descricoes_snipc for item in sublist] # Converte lista de listas para lista"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d87e2d",
   "metadata": {},
   "source": [
    "# Criando Matrizes de Similaridade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c86b2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Levenshtein\n",
    "df_levenshtein = np.zeros((len(descricoes_pof), len(descricoes_snipc)))\n",
    "df_levenshtein = pd.DataFrame(df_levenshtein, columns = descricoes_snipc,\n",
    "index = descricoes_pof)\n",
    "\n",
    "## Jaro\n",
    "df_jaro = np.zeros((len(descricoes_pof), len(descricoes_snipc)))\n",
    "df_jaro = pd.DataFrame(df_jaro, columns = descricoes_snipc,\n",
    "index = descricoes_pof)\n",
    "\n",
    "## Jaccard\n",
    "df_jaccard = np.zeros((len(descricoes_pof), len(descricoes_snipc)))\n",
    "df_jaccard = pd.DataFrame(df_jaccard, columns = descricoes_snipc,\n",
    "index = descricoes_pof)\n",
    "\n",
    "## TF-IDF\n",
    "df_tfidf = np.zeros((len(descricoes_pof), len(descricoes_snipc)))\n",
    "df_tfidf = pd.DataFrame(df_tfidf, columns = descricoes_snipc,\n",
    "index = descricoes_pof)\n",
    "\n",
    "## Word2Vec\n",
    "df_word2vec_soma = np.zeros((len(descricoes_pof), len(descricoes_snipc)))\n",
    "df_word2vec_soma = pd.DataFrame(df_word2vec_soma, columns = descricoes_snipc,\n",
    "index = descricoes_pof)\n",
    "df_word2vec_media = np.zeros((len(descricoes_pof), len(descricoes_snipc)))\n",
    "df_word2vec_media = pd.DataFrame(df_word2vec_media, columns = descricoes_snipc,\n",
    "index = descricoes_pof)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da119136",
   "metadata": {},
   "source": [
    "# Calculando Similaridade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffb4f21",
   "metadata": {},
   "source": [
    "## Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cabc514d",
   "metadata": {},
   "outputs": [],
   "source": [
    "levenshtein = NormalizedLevenshtein()\n",
    "contador = 0\n",
    "for palavra_pof in df_levenshtein.index:\n",
    "    for palavra_snipc in df_levenshtein.columns:\n",
    "        df_levenshtein.at[palavra_pof, palavra_snipc] = levenshtein.similarity(palavra_pof, palavra_snipc)\n",
    "    contador = contador + 1\n",
    "    if contador % 700 == 0 or contador == 3305:\n",
    "        print(contador / df_levenshtein.shape[0] * 100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "065a85b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_resultados = \"C:\\\\Users\\\\aamma\\\\OneDrive\\\\ENCE\\\\TCC\\\\REFAZENDO EXPERIMENTO\\\\Resultados\"\n",
    "os.chdir(path_resultados)\n",
    "df_levenshtein.to_excel(\"Levenshtein_g9_MS.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1151d0e0",
   "metadata": {},
   "source": [
    "## Jaro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6872f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "jaro = JaroWinkler()\n",
    "contador = 0\n",
    "for palavra_pof in df_jaro.index:\n",
    "    for palavra_snipc in df_jaro.columns:\n",
    "        df_jaro.at[palavra_pof, palavra_snipc] = jaro.similarity(palavra_pof, palavra_snipc)\n",
    "    contador = contador + 1\n",
    "    if contador % 700 == 0 or contador == 3305:\n",
    "        print(contador / df_jaro.shape[0] * 100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1091c365",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(path_resultados)\n",
    "df_jaro.to_excel(\"Jaro_g9_MS.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663a17c6",
   "metadata": {},
   "source": [
    "## Jaccard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e901e379",
   "metadata": {},
   "outputs": [],
   "source": [
    "contador = 0\n",
    "for palavra_pof in df_jaccard.index:\n",
    "    for palavra_snipc in df_jaccard.columns:\n",
    "        tok_pof = set(palavra_pof.split())\n",
    "        tok_snipc = set(palavra_snipc.split())\n",
    "        numerador = tok_pof & tok_snipc\n",
    "        denominador = tok_pof | tok_snipc\n",
    "        df_jaccard.at[palavra_pof, palavra_snipc] = len(numerador) / len(denominador)\n",
    "    contador = contador + 1\n",
    "    if contador % 700 == 0 or contador == 3305:\n",
    "        print(contador / df_jaccard.shape[0] * 100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c62b68ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(path_resultados)\n",
    "df_jaccard.to_excel(\"Jaccard_g9_MS.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241ff78f",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1dde7212",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Juntando Todas as Descrições e Removendo duplicatas\n",
    "todas_descricoes = descricoes_pof + descricoes_snipc\n",
    "todas_descricoes = pd.Series(todas_descricoes).drop_duplicates().to_list()\n",
    "\n",
    "# Calculando valores TF-IDF\n",
    "tfidf_matrix = vectorizer.fit_transform(todas_descricoes)\n",
    "\n",
    "# Transformando Matriz TF-IDF em DF\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), index=todas_descricoes, columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# Filtrando por pesquisas\n",
    "tfidf_snipc = tfidf_df.filter(items = descricoes_snipc, axis = 0)\n",
    "tfidf_pof = tfidf_df.filter(items = descricoes_pof, axis = 0)\n",
    "\n",
    "## Calculando Cosseno e transformando em DF\n",
    "cosine_sim = cosine_similarity(tfidf_pof, tfidf_snipc)\n",
    "df_tfidf = pd.DataFrame(cosine_sim, index = descricoes_pof, columns = descricoes_snipc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a598184",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(path_resultados)\n",
    "df_tfidf.to_excel(\"TFIDF_g9_MS.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e705dc",
   "metadata": {},
   "source": [
    "# Word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d0df050",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(path_embeddings)\n",
    "os.getcwd()\n",
    "model = KeyedVectors.load_word2vec_format(\"skip_s300.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89d56093",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(path_bases)\n",
    "tokens_all = pd.read_excel(\"Tokens_All_g9.xlsx\")\n",
    "tokens_all = tokens_all.values.tolist()\n",
    "tokens_all = [item for sublist in tokens_all for item in sublist]\n",
    "vocab_set = set(model.index_to_key)\n",
    "keep_set = set(tokens_all)\n",
    "drop_set = vocab_set - keep_set\n",
    "for word in drop_set:\n",
    "    del model.key_to_index[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0927d7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_nc = pd.read_excel(\"Tokens_All_NC_g9.xlsx\")\n",
    "tokens_nc = tokens_nc.values.tolist()\n",
    "tokens_nc = [item for sublist in tokens_nc for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e262b74d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mijãozinho', 'umbigueiro', 'acortinado']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f79b57ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz_aux = np.zeros((300, ), dtype = \"float32\")\n",
    "for token in tokens_nc:\n",
    "    model[token] = matriz_aux"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6d25e9",
   "metadata": {},
   "source": [
    "## Soma de Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b7ba3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_soma(sentence, model, num_features, word_set):\n",
    "    words = sentence.split()\n",
    "    feature_vec = np.zeros((num_features, ), dtype = \"float32\")\n",
    "    for word in words:\n",
    "        if word in word_set:\n",
    "            feature_vec = np.add(feature_vec, model[word])\n",
    "    model[sentence] = feature_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5deb9314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 %\n",
      "4.901960784313726 %\n",
      "9.803921568627452 %\n",
      "14.705882352941178 %\n",
      "19.607843137254903 %\n",
      "24.509803921568626 %\n",
      "29.411764705882355 %\n",
      "34.31372549019608 %\n",
      "39.21568627450981 %\n",
      "44.11764705882353 %\n",
      "49.01960784313725 %\n",
      "53.92156862745098 %\n",
      "58.82352941176471 %\n",
      "63.725490196078425 %\n",
      "68.62745098039215 %\n",
      "73.52941176470588 %\n",
      "78.43137254901961 %\n",
      "83.33333333333334 %\n",
      "88.23529411764706 %\n",
      "93.13725490196079 %\n",
      "98.0392156862745 %\n"
     ]
    }
   ],
   "source": [
    "word_set = set(model.index_to_key)\n",
    "todas_descricoes = descricoes_pof + descricoes_snipc\n",
    "contador = 0\n",
    "for descricao in todas_descricoes:\n",
    "    embedding_soma(descricao, model, 300, word_set)\n",
    "    if contador % 10 == 0 or contador == 4592:\n",
    "        print(contador / len(todas_descricoes) * 100, \"%\")\n",
    "    contador = contador + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d88cdf38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.936507936507936 %\n",
      "15.873015873015872 %\n",
      "23.809523809523807 %\n",
      "31.746031746031743 %\n",
      "39.682539682539684 %\n",
      "47.61904761904761 %\n",
      "55.55555555555556 %\n",
      "63.49206349206349 %\n",
      "71.42857142857143 %\n",
      "79.36507936507937 %\n",
      "87.3015873015873 %\n",
      "95.23809523809523 %\n"
     ]
    }
   ],
   "source": [
    "contador = 0\n",
    "for palavra_pof in df_word2vec_soma.index:\n",
    "    for palavra_snipc in df_word2vec_soma.columns:\n",
    "        df_word2vec_soma.at[palavra_pof, palavra_snipc] = model.similarity(palavra_pof, palavra_snipc)\n",
    "    contador = contador + 1\n",
    "    if contador % 10 == 0 or contador == 3376:\n",
    "        print(contador / df_word2vec_soma.shape[0] * 100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f67716f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(path_resultados)\n",
    "df_word2vec_soma.to_excel(\"Word2VecSoma_g9_MS.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8dbeb53",
   "metadata": {},
   "source": [
    "## Word2Vec Média"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3ded131a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_media(sentence, model, num_features, word_set):\n",
    "    words = sentence.split()\n",
    "    n_words = 0\n",
    "    feature_vec = np.zeros((num_features, ), dtype = \"float32\")\n",
    "    for word in words:\n",
    "        if word in word_set:\n",
    "            feature_vec = np.add(feature_vec, model[word])\n",
    "            n_words = n_words + 1\n",
    "    model[sentence] = feature_vec / n_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "406dc9f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 %\n",
      "4.901960784313726 %\n",
      "9.803921568627452 %\n",
      "14.705882352941178 %\n",
      "19.607843137254903 %\n",
      "24.509803921568626 %\n",
      "29.411764705882355 %\n",
      "34.31372549019608 %\n",
      "39.21568627450981 %\n",
      "44.11764705882353 %\n",
      "49.01960784313725 %\n",
      "53.92156862745098 %\n",
      "58.82352941176471 %\n",
      "63.725490196078425 %\n",
      "68.62745098039215 %\n",
      "73.52941176470588 %\n",
      "78.43137254901961 %\n",
      "83.33333333333334 %\n",
      "88.23529411764706 %\n",
      "93.13725490196079 %\n",
      "98.0392156862745 %\n"
     ]
    }
   ],
   "source": [
    "word_set = set(model.index_to_key)\n",
    "todas_descricoes = descricoes_pof + descricoes_snipc\n",
    "contador = 0\n",
    "for descricao in todas_descricoes:\n",
    "    embedding_media(descricao, model, 300, word_set)\n",
    "    if contador % 10 == 0 or contador == 4592:\n",
    "        print(contador / len(todas_descricoes) * 100, \"%\")\n",
    "    contador = contador + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5ec38f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.936507936507936 %\n",
      "15.873015873015872 %\n",
      "23.809523809523807 %\n",
      "31.746031746031743 %\n",
      "39.682539682539684 %\n",
      "47.61904761904761 %\n",
      "55.55555555555556 %\n",
      "63.49206349206349 %\n",
      "71.42857142857143 %\n",
      "79.36507936507937 %\n",
      "87.3015873015873 %\n",
      "95.23809523809523 %\n"
     ]
    }
   ],
   "source": [
    "contador = 0\n",
    "for palavra_pof in df_word2vec_media.index:\n",
    "    for palavra_snipc in df_word2vec_media.columns:\n",
    "        df_word2vec_media.at[palavra_pof, palavra_snipc] = model.similarity(palavra_pof, palavra_snipc)\n",
    "    contador = contador + 1\n",
    "    if contador % 10 == 0 or contador == 3376:\n",
    "        print(contador / df_word2vec_media.shape[0] * 100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "877c7a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(path_resultados)\n",
    "df_word2vec_media.to_excel(\"Word2VecMedia_g9_MS.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339c9226",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b2bf110c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6387343a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2079efd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
